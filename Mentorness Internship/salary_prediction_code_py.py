# -*- coding: utf-8 -*-
"""Salary Prediction Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-gcoO_N3AmsgbmI-5QUCprxM4yrH6qV0

# **Project Title : Salary Prediction**

# **Exploratory Data Analysis**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

pd.read_csv('Salary Prediction of Data Professions.csv')

data=pd.read_csv('Salary Prediction of Data Professions.csv')
print(data)

data.info()

"""**Descriptive statistics**"""

data.describe()

rows, columns = data.shape
print(f'The DataFrame has {rows} rows and {columns} columns.')

"""# **Feature Engineering**

# **Drop unwanted columns**
***
"""

data = data.drop(data.columns[[0,1,2,6,9,10]], axis=1)
data.to_csv('Salary Prediction of Data Professions.csv', index=False)

data['DOJ'] = pd.to_datetime(data['DOJ'])
data['CURRENT DATE'] = pd.to_datetime(data['CURRENT DATE'])
#Calculate Tenure: Calculate the TENURE as the difference between CURRENT DATE and DOJ in years.
data['TENURE'] = (data['CURRENT DATE'] - data['DOJ']).dt.days / 365

data = data.drop(columns=['DOJ', 'CURRENT DATE'])
data.to_csv('Salary Prediction of Data Professions.csv', index=False)

data.info()
rows, columns = data.shape
print(f'The DataFrame has {rows} rows and {columns} columns.')

column=list(data.columns)

column.remove('SALARY')

#Insert the column at the new position:

column.insert(5,'SALARY')

#Reassign the columns to the dataframe:

data= data[column]


data.to_csv('Salary Prediction of Data Professions.csv', index=False)

data.info()

"""**Value Counts and Uniques Values**"""

data["DESIGNATION"].unique()

data["DESIGNATION"].value_counts()

data["UNIT"].unique()

data["UNIT"].value_counts()

"""# **Data Preprocessing**

# **Checking and dropping missing values**
"""

missing_values = data.isna().sum()
print("Number of missing values in each column:")
print(missing_values)

total_missing_values = data.isna().sum().sum()
print(f"\nTotal number of missing values in the dataset: {total_missing_values}")

data.isna()

data.dropna(inplace=True)
data.to_csv('Salary Prediction of Data Professions.csv', index=False)

missing_values = data.isna().sum()
print("Number of missing values in each column:")
print(missing_values)

total_missing_values = data.isna().sum().sum()
print(f"\nTotal number of missing values in the dataset: {total_missing_values}")

data.info()

"""# **Visualization and Correlation**"""

correlation = data['PAST EXP'].corr(data['SALARY'])
print(f"Correlation between X and Y: {correlation}")

correlation = data['TENURE'].corr(data['SALARY'])
print(f"Correlation between X and Y: {correlation}")

import seaborn as sns
import matplotlib.pyplot as plt

# Scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=data['PAST EXP'], y=data['SALARY'])
plt.title('Scatter Plot of PAST EXP vs SALARY')
plt.xlabel('PAST EXP')
plt.ylabel('SALARY')
plt.show()

# Heatmap of the correlation matrix
correlation_matrix = data[['PAST EXP', 'SALARY']].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix Heatmap')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=data['TENURE'], y=data['SALARY'])
plt.title('Scatter Plot of PAST EXP vs SALARY')
plt.xlabel('PAST EXP')
plt.ylabel('SALARY')
plt.show()

# Heatmap of the correlation matrix
correlation_matrix = data[['TENURE', 'SALARY']].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix Heatmap')
plt.show()

"""# **Encoding Categorical Features**"""

X = data.drop('SALARY', axis=1)
Y = data['SALARY']

print(X)

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

ct = ColumnTransformer(
    transformers=[('encoder', OneHotEncoder(), [0, 1])],
    remainder='passthrough'
)

X = np.array(ct.fit_transform(X))

print(X[:10])

"""# **Splitting Data**"""

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)

print(X_train.shape)

print(X_train[:10])

print(X_test)

print(Y_train)

print(Y_test)

"""# **Scaling Numerical Features**"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train[:, -3:] = sc.fit_transform(X_train[:, -3:])
X_test[:, -3:] = sc.transform(X_test[:, -3:])

print(X_train[:10])

print(X_test)

"""# **Model Building , Model Training and Evaluating the Models**

# **Linear Regression Model**
"""

# Import necessary libraries
import numpy as np
from sklearn.linear_model import LinearRegression

# Create a linear regression model
lr_model = LinearRegression()

# Train the model with the training data
lr_model.fit(X_train, Y_train)

Y_predlr = lr_model.predict(X_test)
print(Y_predlr)

print(Y_predlr[:10])

"""# **Evaluating linear regression model**



"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
print(f"Model: Linear Regression")
print(f"Mean Absolute Error (MAE): {mean_absolute_error(Y_test, Y_predlr)}")
print(f"Mean Squared Error (MSE): {mean_squared_error(Y_test, Y_predlr)}")
print(f"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(Y_test,Y_predlr))}")
print(f"R-squared (R2) Score: {r2_score(Y_test, Y_predlr)}\n")

"""# **DecisionTreeRegressor Model**"""

import numpy as np
from sklearn.tree import DecisionTreeRegressor

dtr_model = DecisionTreeRegressor()

dtr_model.fit(X_train, Y_train)

Y_preddtr = dtr_model.predict(X_test)
print(Y_preddtr)

"""# **Evaluating Decision Tree Regresssor Model**"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
print(f"Model: DecisionTreeRegressor")
print(f"Mean Absolute Error (MAE): {mean_absolute_error(Y_test, Y_preddtr)}")
print(f"Mean Squared Error (MSE): {mean_squared_error(Y_test, Y_preddtr)}")
print(f"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(Y_test,Y_preddtr))}")
print(f"R-squared (R2) Score: {r2_score(Y_test, Y_preddtr)}\n")

"""# **Random Forest Regressor Model**"""

import numpy as np
from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor()

rf_model.fit(X_train, Y_train)

Y_predrf = rf_model.predict(X_test)
print(Y_predrf)

"""# **Evaluating Random Forest Regressor Model**"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
print(f"Model:RandomForestRegressor")
print(f"Mean Absolute Error (MAE): {mean_absolute_error(Y_test, Y_predrf)}")
print(f"Mean Squared Error (MSE): {mean_squared_error(Y_test, Y_predrf)}")
print(f"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(Y_test,Y_predrf))}")
print(f"R-squared (R2) Score: {r2_score(Y_test, Y_predrf)}\n")

"""# **Gradient Booster Regressor Model**"""

import numpy as np
from sklearn.ensemble import GradientBoostingRegressor

gb_model = GradientBoostingRegressor()

gb_model.fit(X_train, Y_train)

Y_predgb = gb_model.predict(X_test)
print(Y_predgb)

"""# **Evaluating Gradient Booster Regressor Model**"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
print(f"Model: GradientBoostingRegressor")
print(f"Mean Absolute Error (MAE): {mean_absolute_error(Y_test, Y_predgb)}")
print(f"Mean Squared Error (MSE): {mean_squared_error(Y_test, Y_predgb)}")
print(f"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(Y_test,Y_predgb))}")
print(f"R-squared (R2) Score: {r2_score(Y_test, Y_predgb)}\n")

"""**The Random Forest Regressor has the best overall performance, as it has the lowest MSE, the lowest RMSE, and the highest RÂ² score, indicating it explains the most variance in the data and has the best predictive accuracy among the models compared. The Linear Regression model has a slightly lower MAE, but its other metrics are not as strong as those of the RandomForestRegressor. Therefore, Random Forest Regressor is the best model among the four provided. So the final prediction is made using the Random Forest Regressor**

# **Function to get user Input and Preprocess the input**
"""

def predict_salary(designation, unit, tenure, past_exp, ratings):
    input_data = {
        'DESIGNATION': designation,
        'UNIT': unit,
        'TENURE': tenure,
        'PAST EXP': past_exp,
        'RATINGS': ratings
    }

    input_df = pd.DataFrame([input_data])

    # Encode the categorical features
    input_transformed = np.array(ct.transform(input_df))

    # Standardize numerical features
    input_transformed[:, -3:] = sc.transform(input_transformed[:, -3:])

    # Predict the salary
    predicted_salary = rf_model.predict(input_transformed)[0]
    return predicted_salary

"""# **Function to call the previous function to get and display the predicted salary.**"""

def finalprediction():
    designation = input("Enter Designation: ")
    unit = input("Enter Unit: ")
    tenure = float(input("Enter Tenure in years: "))
    past_exp = float(input("Enter Past Experience in years: "))
    ratings = float(input("Enter Ratings: "))

    salary = predict_salary(designation, unit, tenure, past_exp, ratings)
    print(f"Predicted Salary: {salary}")

if __name__ == "__main__":
    finalprediction()